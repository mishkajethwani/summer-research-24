{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mishkajethwani/summer-research-24/blob/main/Actual-Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P6WTnSDbRYgZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5aac1bd-4b3c-4d10-a512-9b36ba7eebff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.8/332.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Important Installations\n",
        "! pip install --quiet langchain\n",
        "! pip install -qU --quiet langchain-openai\n",
        "! pip install --quiet langchain_community\n",
        "! pip install --quiet -qU langchain-openai\n",
        "! pip install --upgrade --quiet langchain langchainhub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88cNGBRKR1-H",
        "outputId": "7bab1c82-26e7-4516-d8f2-f833ea5db134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "#Setting the API key\n",
        "import getpass\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.messages import AIMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5e8B5_LMSSdK"
      },
      "outputs": [],
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "store = {}\n",
        "\n",
        "# Function to get History\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "\n",
        "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def subtract(integer_1: int, integer_2: int) -> int:\n",
        "    \"\"\"Subtract integer_2 from integer_1.\"\"\"\n",
        "    return integer_1 - integer_2\n",
        "\n",
        "@tool\n",
        "def multiply(integer_1: int, integer_2: int) -> int:\n",
        "    \"\"\"Multiply two integers.\"\"\"\n",
        "    return integer_1 * integer_2\n",
        "\n",
        "@tool\n",
        "def divide(integer_1: float, integer_2: float) -> float:\n",
        "    \"\"\"Divide integer_1 by integer_2. Returns a float.\"\"\"\n",
        "    return integer_1 / integer_2\n",
        "\n",
        "@tool\n",
        "def modulo(integer_1: int, integer_2: int) -> int:\n",
        "    \"\"\"Calculate the remainder of division.\"\"\"\n",
        "    return integer_1 % integer_2\n",
        "\n",
        "\n",
        "@tool\n",
        "def add(first_int: int, second_int: int) -> int:\n",
        "    \"Add two integers.\"\n",
        "    return first_int + second_int\n",
        "\n",
        "\n",
        "@tool\n",
        "def exponentiate(base: int, exponent: int) -> int:\n",
        "    \"Exponentiate the base to the exponent power.\"\n",
        "    return base**exponent\n",
        "\n",
        "@tool\n",
        "def factorial(integer_1: int) -> int:\n",
        "    \"\"\"Calculate the factorial of a non-negative integer.\"\"\"\n",
        "    result = 1\n",
        "    for i in range(2, integer_1 + 1):\n",
        "        result *= i\n",
        "    return result\n",
        "\n",
        "tools = [subtract, multiply, divide, modulo, factorial, add, exponentiate]\n",
        "\n",
        "def setup_math_agent():\n",
        "    llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are a precise mathematical calculator. Follow these steps for each calculation:\n",
        "        1. Break down the problem into individual operations.\n",
        "        2. Perform each operation step-by-step, using the appropriate tool for each.\n",
        "        3. Show your work clearly, stating which tool you're using and the numbers you're inputting.\n",
        "        4. Double-check your work and provide the final answer.\n",
        "        Available tools: subtract, multiply, divide, modulo, factorial, add, exponentiate\"\"\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ])\n",
        "\n",
        "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "    return AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "HvdMGVcmT4EO"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "def chat_bot_normal():\n",
        "    session_id = \"abc12\"\n",
        "    config = {\"configurable\": {\"session_id\": session_id}}\n",
        "\n",
        "    print(\"Chatbot: Hello! How can I assist you today?\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        messages = [HumanMessage(content=user_input)]\n",
        "        response = with_message_history.invoke(messages, config)\n",
        "        bot_response = response.content\n",
        "\n",
        "\n",
        "        print(\"Chatbot:\", bot_response)\n"
      ],
      "metadata": {
        "id": "SHUw1DvxfEpk"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "tools = [subtract, multiply, divide, modulo, factorial, add, exponentiate]\n",
        "\n",
        "def setup_math_agent():\n",
        "    llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are a precise mathematical calculator. Follow these steps for each calculation:\n",
        "        1. Break down the problem into individual operations.\n",
        "        2. Perform each operation step-by-step, using the appropriate tool for each.\n",
        "        3. Show your work clearly, stating which tool you're using and the numbers you're inputting.\n",
        "        4. Double-check your work and provide the final answer.\n",
        "        Available tools: subtract, multiply, divide, modulo, factorial, add, exponentiate\"\"\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ])\n",
        "\n",
        "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "    return AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "def chatbot_with_calculator():\n",
        "    llm = ChatOpenAI(temperature=0.7)\n",
        "    math_agent = setup_math_agent()\n",
        "\n",
        "    math_tool = Tool(\n",
        "        name=\"math_calculator\",\n",
        "        func=lambda x: math_agent.invoke({\"input\": x})['output'],\n",
        "        description=\"Performs complex mathematical calculations. Input should be a mathematical problem.\"\n",
        "    )\n",
        "    chatbot_tools = [math_tool]\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "    chatbot_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are a helpful assistant capable of general conversation and mathematical calculations.\n",
        "        For mathematical problems, use the math_calculator tool. For all other queries, respond normally.\n",
        "        Always maintain context from previous messages and use that information in your responses.\n",
        "        If you're not sure about something, admit that you don't know or don't have that information.\"\"\"),\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ])\n",
        "\n",
        "    chatbot_agent = create_openai_tools_agent(llm, chatbot_tools, chatbot_prompt)\n",
        "    chatbot_executor = AgentExecutor(agent=chatbot_agent, tools=chatbot_tools, memory=memory, verbose=True)\n",
        "\n",
        "    print(\"Chatbot: Hello! I'm a chatbot that can also do mathematical calculations. How can I assist you today?\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        result = chatbot_executor.invoke({\"input\": user_input})\n",
        "        bot_response = result['output']\n",
        "\n",
        "chatbot_with_calculator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "xW12HPq3tgJK",
        "outputId": "7e2e6e24-25d1-4af8-eb10-0470aace8335"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot: Hello! I'm a chatbot that can handle conversations and do mathematical calculations. How can I assist you today?\n",
            "You: sum of 2 plus thirty five \n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `math_calculator` with `2 + 35`\n",
            "\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `add` with `{'first_int': 2, 'second_int': 35}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m37\u001b[0m\u001b[32;1m\u001b[1;3mThe sum of 2 and 35 is 37.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mThe sum of 2 and 35 is 37.\u001b[0m\u001b[32;1m\u001b[1;3mThe sum of 2 and 35 is 37.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-1cb1f7b4aa75>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mbot_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mchatbot_with_calculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-1cb1f7b4aa75>\u001b[0m in \u001b[0;36mchatbot_with_calculator\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchatbot_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mbot_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DkzP8_B5f8Tf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec44fa36-5ce1-4e83-bdc6-87a2787d368c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `exponentiate` with `{'base': 3, 'exponent': 5}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m243\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `add` with `{'first_int': 12, 'second_int': 3}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m15\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `multiply` with `{'integer_1': 243, 'integer_2': 15}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m3645\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `exponentiate` with `{'base': 3645, 'exponent': 2}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m13286025\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `subtract` with `{'integer_1': 13286025, 'integer_2': 2}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m13286023\u001b[0m\u001b[32;1m\u001b[1;3mThe final result after following the steps you provided is 13,286,023.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Take 3 to the fifth power and multiply that by the sum of twelve and three, then square the whole result and then finally subtract 2',\n",
              " 'output': 'The final result after following the steps you provided is 13,286,023.'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a helpful assistant skilled in mathematical calculations. The user may not always require tools and may just want to chat. If the user does require a calculation:\n",
        "\n",
        "    For each step of the calculation:\n",
        "    1. Clearly state what operation you're performing.\n",
        "    2. Show the exact numbers you're using, ensuring you use the correct results from previous steps.\n",
        "    3. Use the appropriate tool to perform the calculation.\n",
        "    4. State the result of each step.\n",
        "\n",
        "    After completing all steps, provide the final answer. Double-check your work to ensure accuracy.\"\"\"),\n",
        "    HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"Take 3 to the fifth power and multiply that by the sum of twelve and three, then square the whole result and then finally subtract 2\"\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qBOJOiSe5A3h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPjIseJs6q3PWZwc0qtDAwP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}